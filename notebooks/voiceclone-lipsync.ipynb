{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11215755,"sourceType":"datasetVersion","datasetId":7003773},{"sourceId":11311047,"sourceType":"datasetVersion","datasetId":7024241}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install torchvision librosa==0.9.2 opencv-python-headless ffmpeg-python gradio torchaudio tortoise-tts ffmpeg-python\n\nimport os\nimport torch\nimport torchaudio\nimport gradio as gr\nimport subprocess\nimport shutil\nfrom tortoise.api import TextToSpeech\nfrom tortoise.utils.audio import load_audio\n\n# Constants\nWORKING_DIR = \"/kaggle/working/\"\nCLONED_VOICE_PATH = os.path.join(WORKING_DIR, \"cloned_voice1.wav\")\nOUTPUT_VIDEO_PATH = os.path.join(WORKING_DIR, \"lip_sync_result1.mp4\")\n\n# Setup directories\nos.makedirs(WORKING_DIR, exist_ok=True)\nos.makedirs(os.path.join(WORKING_DIR, \"temp\"), exist_ok=True)\n\n# Initialize TTS\ntts = TextToSpeech()\n\ndef generate_voice_clone(audio_file, text, quality):\n    \"\"\"Generate cloned voice and save to fixed location\"\"\"\n    try:\n        # Handle Gradio audio input\n        if isinstance(audio_file, tuple):\n            sample_rate, audio_data = audio_file\n            torchaudio.save(CLONED_VOICE_PATH, torch.from_numpy(audio_data).float(), sample_rate)\n        else:\n            shutil.copy(audio_file, CLONED_VOICE_PATH)\n        \n        # Generate cloned voice\n        voice_samples = [load_audio(CLONED_VOICE_PATH, 22050)]\n        gen = tts.tts_with_preset(\n            text,\n            voice_samples=voice_samples,\n            preset=quality,\n            diffusion_iterations=100\n        )\n        \n        # Save the final output\n        torchaudio.save(CLONED_VOICE_PATH, gen.squeeze(0).cpu(), 24000)\n        \n        return CLONED_VOICE_PATH, \"Voice cloned successfully!\"\n        \n    except Exception as e:\n        return None, f\"Error: {str(e)}\"\n\ndef lip_sync(video_path):\n    \"\"\"Lip-sync using the pre-generated voice with proper preprocessing\"\"\"\n    try:\n        if not os.path.exists(CLONED_VOICE_PATH):\n            return None, \"Please generate voice clone first!\", None\n        \n        # Handle video input\n        # Normalize and copy to working dir\n        video_working_path = os.path.join(WORKING_DIR, \"input_face_video.mp4\")\n\n        if isinstance(video_path, str) and os.path.exists(video_path):\n            shutil.copy(video_path, video_working_path)\n        elif isinstance(video_path, dict) and \"name\" in video_path:\n            shutil.copy(video_path[\"name\"], video_working_path)\n        else:\n            raise Exception(\"Invalid video input or file not found.\")\n\n        \n        # Create directories\n        temp_dir = os.path.join(WORKING_DIR, \"temp\")\n        results_dir = os.path.join(WORKING_DIR, \"results\")\n        os.makedirs(temp_dir, exist_ok=True)\n        os.makedirs(results_dir, exist_ok=True)\n        \n        # Prepare paths\n        processed_video_path = os.path.join(temp_dir, \"preprocessed_input.mp4\")\n        temp_audio_path = os.path.join(temp_dir, \"audio.wav\")\n        temp_output_path = os.path.join(temp_dir, \"result.avi\")\n        final_output_path = os.path.join(results_dir, \"lip_sync_output.mp4\")\n        \n        # Use the CLONED_VOICE_PATH as the audio source\n        cloned_audio_path = CLONED_VOICE_PATH\n        \n        # Convert cloned audio to 16000Hz\n        cmd = f\"ffmpeg -y -i {cloned_audio_path} -ar 16000 {temp_audio_path}\"\n        subprocess.run(cmd, shell=True, check=True)\n        \n        # Preprocess video\n        cmd = f'ffmpeg -y -i \"{video_path}\" -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p -strict -2 \"{processed_video_path}\"'\n        subprocess.run(cmd, shell=True, check=True)\n        \n        # Run Wav2Lip with parameters matching the working version\n        cmd = f\"\"\"\n        python /kaggle/input/wav2lip/Wav2Lip/inference.py \\\n        --checkpoint_path /kaggle/input/wav2lip/Wav2Lip/checkpoints/wav2lip_gan.pth \\\n        --face \"{processed_video_path}\" \\\n        --audio \"{temp_audio_path}\" \\\n        --outfile \"{temp_output_path}\" \\\n        --resize_factor 1 \\\n        --fps 25 \\\n        --face_det_batch_size 4 \\\n        --wav2lip_batch_size 16 \\\n        --nosmooth\n        \"\"\"\n        subprocess.run(cmd, shell=True, check=True)\n        \n        # Convert output to MP4\n        cmd = f'ffmpeg -y -i \"{temp_output_path}\" -vcodec libx264 -acodec aac \"{final_output_path}\"'\n        subprocess.run(cmd, shell=True, check=True)\n        \n        if os.path.exists(final_output_path):\n            return final_output_path, \"Lip-sync complete!\", cloned_audio_path\n        else:\n            return None, \"Lip-sync failed - no output generated\", None\n            \n    except subprocess.CalledProcessError as e:\n        return None, f\"Command failed: {e.cmd} with return code {e.returncode}\", None\n    except Exception as e:\n        return None, f\"Error: {str(e)}\", None\n\n# Custom CSS for styling\n\n\n# Custom CSS with improved visibility and modern colors\n\n# Custom CSS with dark theme\ncustom_css = \"\"\"\n.gradio-container {\n    font-family: 'Helvetica', Arial, sans-serif;\n    background: #000000 !important;\n    color: #ffffff !important;\n}\n.header {\n    text-align: center;\n    margin-bottom: 20px;\n    padding: 20px;\n    background: #1a1a1a !important;\n    border-radius: 12px;\n    box-shadow: 0 4px 6px rgba(0,0,0,0.3);\n}\n.header h1 {\n    color: #ffffff !important;\n    margin-bottom: 10px;\n    font-weight: 700;\n}\n.header p {\n    color: #b3b3b3 !important;\n    font-size: 1.1em;\n}\n.tab {\n    background: #2d2d2d !important;\n    border-radius: 12px;\n    padding: 20px;\n    box-shadow: 0 4px 12px rgba(0,0,0,0.3);\n    border: 1px solid #404040 !important;\n    color: #ffffff !important;\n}\n.input-section, .output-section {\n    background: #3d3d3d !important;\n    border-radius: 12px;\n    padding: 20px;\n    margin-bottom: 20px;\n    box-shadow: 0 2px 8px rgba(0,0,0,0.3);\n    border: 1px solid #505050 !important;\n    color: #ffffff !important;\n}\n.input-section h2, .output-section h2 {\n    color: #ffffff !important;\n    margin-top: 0;\n    padding-bottom: 12px;\n    border-bottom: 2px solid #505050 !important;\n    font-weight: 600;\n}\n.btn {\n    background: linear-gradient(135deg, #4a6baf 0%, #3a5a9f 100%) !important;\n    color: white !important;\n    border: none !important;\n    padding: 12px 24px !important;\n    border-radius: 8px !important;\n    font-weight: 600 !important;\n    box-shadow: 0 2px 4px rgba(0,0,0,0.3) !important;\n    transition: all 0.3s ease !important;\n}\n.btn:hover {\n    transform: translateY(-2px) !important;\n    box-shadow: 0 4px 8px rgba(0,0,0,0.4) !important;\n    background: linear-gradient(135deg, #3a5a9f 0%, #2a4a8f 100%) !important;\n}\n.status-box {\n    background: #2d2d2d !important;\n    padding: 12px;\n    border-radius: 8px;\n    border-left: 4px solid #4a6baf !important;\n    font-family: monospace;\n    color: #ffffff !important;\n}\nlabel {\n    font-weight: 500 !important;\n    color: #cccccc !important;\n    margin-bottom: 8px !important;\n}\n.gr-interface {\n    background: transparent !important;\n}\n.tabs {\n    gap: 16px !important;\n}\n.gr-box {\n    border-color: #505050 !important;\n    background: #3d3d3d !important;\n    color: white !important;\n}\ninput, textarea, select {\n    background: #2d2d2d !important;\n    color: white !important;\n    border-color: #505050 !important;\n}\n\"\"\"\n\n# Gradio Interface with dark theme\nwith gr.Blocks(css=custom_css, theme=gr.themes.Default(primary_hue=\"blue\")) as app:\n    with gr.Column():\n        gr.Markdown(\"\"\"\n        <div class=\"header\">\n            <h1>üé§ Voice Cloning + üé¨ Lip Sync Studio</h1>\n            <p>Transform any voice and create perfectly synced videos with cutting-edge AI</p>\n        </div>\n        \"\"\")\n    \n    with gr.Tabs():\n        with gr.Tab(\"1. Voice Cloning\", elem_classes=\"tab\"):\n            with gr.Row(equal_height=True):\n                with gr.Column(scale=1, elem_classes=\"input-section\"):\n                    gr.Markdown(\"### üõ†Ô∏è Input Parameters\")\n                    audio_input = gr.Audio(label=\"üéôÔ∏è Reference Voice Sample\", \n                                         type=\"filepath\",\n                                         elem_id=\"audio-input\")\n                    text_input = gr.Textbox(label=\"üìù Text to Speak\", \n                                           placeholder=\"Type what you want the cloned voice to say...\",\n                                           lines=3)\n                    quality = gr.Dropdown(\n                        label=\"‚ö° Quality Preset\", \n                        choices=[\"fast\", \"standard\", \"high_quality\"], \n                        value=\"standard\",\n                        info=\"Higher quality = better results but longer processing\"\n                    )\n                    clone_btn = gr.Button(\"‚ú® Generate Cloned Voice\", elem_classes=\"btn\")\n                \n                with gr.Column(scale=1, elem_classes=\"output-section\"):\n                    gr.Markdown(\"### üéß Results\")\n                    voice_output = gr.Audio(label=\"üîä Cloned Voice Output\", \n                                           interactive=False,\n                                           elem_id=\"audio-output\")\n                    with gr.Group():\n                        gr.Markdown(\"**üìä Status**\")\n                        clone_status = gr.Textbox(label=\"\", \n                                                show_label=False, \n                                                elem_classes=\"status-box\",\n                                                placeholder=\"Waiting for voice generation...\")\n        \n        with gr.Tab(\"2. Lip Sync\", elem_classes=\"tab\"):\n            with gr.Row(equal_height=True):\n                with gr.Column(scale=1, elem_classes=\"input-section\"):\n                    gr.Markdown(\"### üé• Video Input\")\n                    video_input = gr.Video(label=\"üìΩÔ∏è Upload Target Video\", \n                                         elem_id=\"video-input\")\n                    sync_btn = gr.Button(\"üé¨ Generate Lip Sync\", elem_classes=\"btn\")\n                    gr.Markdown(\"\"\"\n                    <div style=\"color: #b3b3b3; font-size: 0.9em; margin-top: 10px;\">\n                    ‚ÑπÔ∏è You must generate a voice clone in the first tab before lip-syncing.\n                    </div>\n                    \"\"\")\n                \n                with gr.Column(scale=1, elem_classes=\"output-section\"):\n                    gr.Markdown(\"### üéûÔ∏è Final Output\")\n                    video_output = gr.Video(label=\"üì∫ Lip-Synced Video\", \n                                         elem_id=\"video-output\")\n                    with gr.Group():\n                        gr.Markdown(\"**üìä Status**\")\n                        sync_status = gr.Textbox(label=\"\", \n                                               show_label=False, \n                                               elem_classes=\"status-box\",\n                                               placeholder=\"Waiting for lip sync...\")\n                    voice_review = gr.Audio(label=\"üîà Voice Used for Lip Sync\", \n                                          interactive=False)\n    \n    # Voice cloning action\n    clone_btn.click(\n        fn=generate_voice_clone,\n        inputs=[audio_input, text_input, quality],\n        outputs=[voice_output, clone_status]\n    )\n    \n    # Lip-sync action\n    sync_btn.click(\n        fn=lip_sync,\n        inputs=[video_input],\n        outputs=[video_output, sync_status, voice_review]\n    )\n\napp.launch(share=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}